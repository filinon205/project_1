{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dill\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "from sklearn.metrics import roc_auc_score,roc_curve\n",
    "from sklearn.metrics import f1_score\n",
    "#working with text\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#normalizing data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#pipeline\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.metrics import precision_score,recall_score\n",
    "#imputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "import sklearn.datasets\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.io as pio\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "pd.options.display.max_columns = 150\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Анализ данных\n",
    "Сборник SMS-спама - это набор SMS-сообщений с тегами, собранных для исследования SMS-спама. Он содержит один набор SMS-сообщений на английском языке из 5 574 сообщений, помеченных как «легитимные» или «спам».\n",
    "\n",
    "файлы содержат по одному сообщению в строке. Каждая строка состоит из двух столбцов: v1 содержит метку (ветчина или спам), а v2 содержит необработанный текст.\n",
    "\n",
    "Этот корпус был получен из бесплатных или бесплатных источников для исследований в Интернете:\n",
    "\n",
    "-> Коллекция из 425 спам-сообщений SMS была вручную извлечена с веб-сайта Grumbletext. Это британский форум, на котором пользователи сотовых телефонов публично заявляют о спам-сообщениях в виде SMS, причем большинство из них не сообщает о полученном спаме. Идентификация текста спам-сообщений в претензиях - очень сложная и трудоемкая задача, требующая тщательного сканирования сотен веб-страниц. Веб-сайт Grumbletext: [Веб-ссылка] .\n",
    "-> Подмножество из 3 375 SMS, случайно выбранных любительских сообщений из NUS SMS Corpus (NSC), который представляет собой набор данных из примерно 10 000 легитимных сообщений, собранных для исследований в Департаменте компьютерных наук Национального университета Сингапура. Сообщения в основном исходят от сингапурцев и в основном от студентов, обучающихся в университете. Эти сообщения были получены от добровольцев, которые были осведомлены о том, что их вклад станет общедоступным. Корпус NUS SMS доступен по адресу: [Web Link] .\n",
    "-> Список из 450 радиолюбительских SMS-сообщений, собранных из докторской диссертации Кэролайн Тэг, доступен на [Web Link] .\n",
    "-> Наконец, мы добавили корпус SMS Spam Corpus v.0.1 Big. Он содержит 1 002 любительских SMS-сообщения и 322 спам-сообщения, и он общедоступен по адресу: [Web Link] . Этот корпус использовался в следующих академических исследованиях:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = pd.read_csv(r\"C:\\Users\\nikita.saprykin\\Desktop\\Машинное обучение в бизнесе\\new\\spam.csv\",  encoding='ISO-8859-1')\n",
    "df_.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Пропущенные значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as msno\n",
    "msno.bar(df_, color = '#6389df', figsize = (6,4))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = df_[['v2','v1']]\n",
    "df_.columns = ['sms','spam']\n",
    "df=pd.DataFrame()\n",
    "mapping = {'spam': 1,'ham': 0}\n",
    "df['sms']=df_['sms']\n",
    "df['spam']=df_['spam'].map(mapping)\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Очистка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate(data):\n",
    "    \n",
    "    print(\"До удаления дубликатов кол-во строк = \",df.shape[0])\n",
    "    data.drop_duplicates(keep=\"first\", inplace=True) \n",
    "    print(\"После удаления дубликатов кол-во строк = \",df.shape[0])\n",
    "    return \"Проверка дубликатов\"\n",
    "\n",
    "remove_duplicate(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_data(data):\n",
    "    total = data.isnull().sum().sort_values(ascending = False)\n",
    "    percent = (data.isnull().sum()/data.isnull().count()*100).sort_values(ascending = False)\n",
    "    return pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_data(data):\n",
    "    total = data.isnull().sum().sort_values(ascending = False)\n",
    "    percent = (data.isnull().sum()/data.isnull().count()*100).sort_values(ascending = False)\n",
    "    return pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df, \n",
    "                                                    df['spam'], test_size=0.33, random_state=42)\n",
    "#save test\n",
    "X_test.to_csv(\"X_test.csv\", index=None)\n",
    "y_test.to_csv(\"y_test.csv\", index=None)\n",
    "#save train\n",
    "X_train.to_csv(\"X_train.csv\", index=None)\n",
    "y_train.to_csv(\"y_train.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.key]\n",
    "    \n",
    "class TextImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key, value):\n",
    "        self.key = key\n",
    "        self.value = value\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X[self.key] = X[self.key].fillna(self.value)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df['sms']\n",
    "target = df['spam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine\n",
    "sms = Pipeline([\n",
    "                ('imputer', TextImputer('sms', '')),\n",
    "                ('selector', ColumnSelector(key='sms')),\n",
    "                ('tfidf', TfidfVectorizer(max_df=0.9, min_df=10))\n",
    "            ])\n",
    "\n",
    "feats = FeatureUnion([('sms', sms),\n",
    "                      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('features',feats),\n",
    "    ('classifier', LogisticRegression()),\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "#Посмотрим, как выглядит наш pipeline\n",
    "pipeline.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pipeline.dill\", \"wb\") as f:\n",
    "    dill.dump(pipeline, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка работоспособности АПИ\n",
    "\n",
    "### клонирование репозитория и создание его образа\n",
    "\n",
    " $ git clone https://github.com/filinon205/project_1.git\n",
    "\n",
    " $ cd flack_docker/\n",
    "\n",
    " $ sudo docker build -t nikita/flack_docker .\n",
    "\n",
    "### Запуск контейнера к которому необходимо обращаться через АПИ\n",
    "\n",
    " $ docker run -d -p 8180:8180 -p 8181:8181 -v C:/Users/nikita.saprykin/Desktop/Машинное обучение в бизнесе/flack_docker/app/models:/app/app/models nikita/flack_docker/pipeline.dill\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка работоспособности и качества пайплайна\n",
    "roc_auc_score  98%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score,roc_curve\n",
    "import dill\n",
    "dill._dill._reverse_typemap['ClassType'] = type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(\"X_test.csv\")\n",
    "y_test = pd.read_csv(\"y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sms</th>\n",
       "      <th>is_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Funny fact Nobody teaches volcanoes 2 erupt, t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I sent my scores to sophas and i had to do sec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We know someone who you know that fancies you....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 sms  is_spam\n",
       "0  Funny fact Nobody teaches volcanoes 2 erupt, t...        0\n",
       "1  I sent my scores to sophas and i had to do sec...        0\n",
       "2  We know someone who you know that fancies you....        1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pipeline.dill', 'rb') as in_strm:\n",
    "#with open('\"app/models/my_1st_pipeline.dill\"', 'rb') as in_strm:\n",
    "    pipeline = dill.load(in_strm)\n",
    "    \n",
    "predictions = pipeline.predict_proba(X_test)\n",
    "pd.DataFrame({'preds': predictions[:, 1]}).to_csv(\"test_predictions.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9796411318150448"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_score=predictions[:, 1][:], y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9851996879407087"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.9851996879407087"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score,roc_curve\n",
    "from urllib import request, parse\n",
    "\n",
    "X_test = pd.read_csv(\"X_test.csv\")\n",
    "y_test = pd.read_csv(\"y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Funny fact Nobody teaches volcanoes 2 erupt, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I sent my scores to sophas and i had to do sec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We know someone who you know that fancies you....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 sms\n",
       "0  Funny fact Nobody teaches volcanoes 2 erupt, t...\n",
       "1  I sent my scores to sophas and i had to do sec...\n",
       "2  We know someone who you know that fancies you...."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[['sms']].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import json      \n",
    "\n",
    "\n",
    "def get_prediction(x):\n",
    "    sms = x\n",
    "    body = {'sms': sms, \n",
    "            } \n",
    "\n",
    "    myurl = \"http://0.0.0.0:8180/predict\"\n",
    "    req = urllib.request.Request(myurl)\n",
    "    req.add_header('Content-Type', 'application/json; charset=utf-8')\n",
    "    jsondata = json.dumps(body)\n",
    "    jsondataasbytes = jsondata.encode('utf-8')   # needs to be bytes\n",
    "    req.add_header('Content-Length', len(jsondataasbytes))\n",
    "    #print (jsondataasbytes)\n",
    "    response = urllib.request.urlopen(req, jsondataasbytes)\n",
    "    return json.loads(response.read())['is_spam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7948225582927236"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Проверка\n",
    "get_prediction('Your question this week will enter u in our draw 4 cash.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# тестовый массив\n",
    "predictions = X_test['sms'].apply(lambda x: get_prediction(x), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.312016\n",
       "1       0.005498\n",
       "2       0.816170\n",
       "3       0.003577\n",
       "4       0.999995\n",
       "          ...   \n",
       "1834    0.000263\n",
       "1835    0.001471\n",
       "1836    0.013453\n",
       "1837    0.372728\n",
       "1838    0.965014\n",
       "Name: sms, Length: 1839, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# массив\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9796411318150448"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Качество\n",
    "roc_auc_score(y_score=predictions.values, y_true=y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
